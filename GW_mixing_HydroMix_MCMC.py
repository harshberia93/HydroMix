#################################################################################################################################
'''
Created on: 18th July 2019 (Harsh Beria) 
Last updated on 
What it does?

Runs a MCMC implementation of HydroMix to estimate snow ratio in groundwater with the isotopic ratios generated by the script 
GW_conceptual.py
The main feature is that this script can use different time periods during the computation of snow ratio

SourceFiles used:
OutputFiles/GW_conceptual/	
	
OutputFiles processed:
Figures made:
'''
#################################################################################################################################
# %% Imports

from __future__ import division
import numpy as np
import random, datetime, calendar
import pandas as pd
import matplotlib.pyplot as plt

#################################################################################################################################
# %% Custom functions

def Random_walk(initialParam, paramLimit, step):
	'''
	Generates the new parameter set

	initialParam => Initial parameter values (LIST)
	paramLimit => Lower and upper limits of the list of parameters ([[lambdaLowVal, lambdaHighVal], [StdLowVal, StdHighVal])
	step => Defines the maximum extent of jump from the current parameter state (in %)

	Returns the updated parameter state (LIST)
	'''
	
	stepChange = [(i[1]-i[0])*0.005*step for i in paramLimit] # List of step changes
	
	# Lower and upper limits for all parameters
	lowerParLimit = [max(initialParam[index]-stepChange[index], paramLimit[index][0]) for index in range(len(initialParam))]
	upperParLimit = [min(initialParam[index]+stepChange[index], paramLimit[index][1]) for index in range(len(initialParam))]
	
	# Generating new parameter set by sampling uniformly in the given range
	newParam = [np.random.uniform(lowerParLimit[index], upperParLimit[index]) for index in range(len(initialParam))]
	
	return (newParam) # Returns the list containing new parameters

def HydroMix(source1, source2, mixture, stdDev, param_init, param_limit, nb_iter, RandomWalkStep=5):
	'''
	Contains the core of HydroMix
	
	source1 => Concentration data of source 1
	source2 => Concentration data of source 2
	mixture => Concentration data of the mixture made up of a linear combination of sources 1 and 2
	stdDev => Standard deviation of the mixture (specified apriori and not calibrated)
	param_init => Initial value of the list of parameters ([lambdaValue, stdValue])
	param_limit => Lower and upper limits of the list of parameters ([[lambdaLowVal, lambdaHighVal])
	nb_iter => Number of MCMC runs
	RandomWalkStep => In percentage to define the maximum extent of jump from the current parameter state

	Returns a tuple containing [[LOG LIKELIHOOD VALUES], [PARAMETER VALUES]]
	
	'''

	logLikelihoodLis, paramLis = [], [param_init]
	std_param = stdDev
	for i in range(nb_iter):
		
		# Compute new parameter set
		updatedParam = Random_walk(paramLis[-1], param_limit, RandomWalkStep)
	
		# Log likelihood computation
		lambda_param = updatedParam[0]
		temp_loglikelihood = []
		for temp_mix in mixture:	
			temp_value = 0.
			temp_residual = []
			for temp_s1 in source1:
				for temp_s2 in source2:
					temp_estimated_mix = lambda_param*1.*temp_s1 + (1-lambda_param)*temp_s2*1.
					
					# Log likelihood computation
					temp_value -= (0.5* np.log(2 * np.pi * std_param * std_param))
					temp_value -= (0.5*(temp_estimated_mix - temp_mix)*(temp_estimated_mix - temp_mix)) / (std_param*std_param)
					temp_residual.append(temp_estimated_mix-temp_mix)
			
			temp_loglikelihood.append(temp_value)
		LLValue = np.sum(temp_loglikelihood)
	
		# Hastings test
		if (i == 0): # First iteration (accept it)
			logLikelihoodLis.append(LLValue)
		else:
			alpha = np.exp(LLValue - logLikelihoodLis[-1])
			if ( (alpha > 1) or (np.random.rand() > (1-alpha)) ): # Accept the new move
				paramLis.append(updatedParam)
				logLikelihoodLis.append(LLValue)
				
		# For displaying purposes
		if (i%100 == 0):
			print ( "Iteration number:" + str(i+1) + ", Acceptance: " + str(len(logLikelihoodLis)/(i+1)) )
		
	return ((logLikelihoodLis, paramLis))

def HydroMix_weighted(source1, source1Weight, source2, source2Weight, mixture, stdDev, param_init, param_limit, nb_iter, RandomWalkStep=5):
	'''
	Contains the core of HydroMix
	
	source1 => Concentration data of source 1
	source1Weight => 
	source2 => Concentration data of source 2
	source2Weight => 
	mixture => Concentration data of the mixture made up of a linear combination of sources 1 and 2
	stdDev => Standard deviation of the mixture (specified apriori and not calibrated)
	param_init => Initial value of the list of parameters ([lambdaValue, stdValue])
	param_limit => Lower and upper limits of the list of parameters ([[lambdaLowVal, lambdaHighVal])
	nb_iter => Number of MCMC runs
	RandomWalkStep => In percentage to define the maximum extent of jump from the current parameter state

	Returns a tuple containing [[LOG LIKELIHOOD VALUES], [PARAMETER VALUES]]
	
	'''

	logLikelihoodLis, paramLis = [], [param_init]
	std_param = stdDev
	for i in range(nb_iter):
		
		# Compute new parameter set
		updatedParam = Random_walk(paramLis[-1], param_limit, RandomWalkStep)
	
		# Log likelihood computation
		lambda_param = updatedParam[0]
		temp_loglikelihood = []
		for temp_mix in mixture:	
			temp_value = 0.
			temp_residual = []
			for temp_s1, temp_s1Weight in zip(source1, source1Weight):
				for temp_s2, temp_s2Weight in zip(source2, source2Weight):
					temp_estimated_mix = lambda_param*1.*temp_s1 + (1-lambda_param)*temp_s2*1.
					
					# Weight computation
					temp_weight = temp_s1Weight * temp_s2Weight
					
					# Log likelihood computation		
					temp_value -= temp_weight * (0.5* np.log(2 * np.pi * std_param * std_param))
					temp_value -= temp_weight * (0.5*(temp_estimated_mix - temp_mix)*(temp_estimated_mix - temp_mix)) / (std_param*std_param)
					temp_residual.append(temp_estimated_mix-temp_mix)
			
			temp_loglikelihood.append(temp_value)
		LLValue = np.sum(temp_loglikelihood)
		
		# Hastings test
		if (i == 0): # First iteration (accept it)
			logLikelihoodLis.append(LLValue)
		else:
			alpha = np.exp(LLValue - logLikelihoodLis[-1])
			if ( (alpha > 1) or (np.random.rand() > (1-alpha)) ): # Accept the new move
				paramLis.append(updatedParam)
				logLikelihoodLis.append(LLValue)
		
		# For displaying purposes
		if (i%100 == 0):
			print ( "Iteration number:" + str(i+1) + ", Acceptance: " + str(len(logLikelihoodLis)/(i+1)) )
	return ((logLikelihoodLis, paramLis))

# This is a csv writer
import csv
def csv_writer(data, path):
	with open(path, "wb") as csv_file:
		writer = csv.writer(csv_file, delimiter=',')
		for line in data:
			writer.writerow(line)

#################################################################################################################################
# %% Main variables

RAIN_EFF, SNOW_EFF = 0.1, 0.1

# Mixing model parameters
NUMBER_ITERATIONS = 3000
LAMBDA_RANGE = [0., 1.] # LAMBDA values imply the fraction of snow in groundwater
# Number of best simulations using which lambda is computed
BEST_SIM_PER = 5. # In percentage

YEARS = 100 #  Number of years for which simulation was carried out
LAST_YEARS = 2 # Number of years at the end of the timeseries from which isotopic data is sampled

# Options are "Snowfall/Snowmelt", tells us which isotopic ratio is to be used to find groundwater recharge using HydroMix
WHICH_SNOW = "Snowmelt"
WEIGHTED = 1 # 0 => non-weighted mixing, 1 => weighted mixing

JUMP_PERCENTAGE = 5 # In percentage (JUMP_PERCENTAGE/2 in both directions)

PATH = "OutputFiles/GW_conceptual/"
OUTPUTPATH = "OutputFiles/GW_conceptual/Rainfall_" + WHICH_SNOW + "_mixing_last_" + str(LAST_YEARS) + "Yr"
if (WEIGHTED):
	OUTPUTPATH += "_weighted_MCMC/"
else:
	OUTPUTPATH += "_MCMC/"

#################################################################################################################################
# %% Initializing the seeds
np.random.seed(15544) # Setting up a common seed number for numpy function
random.seed(55452) # Setting up random seed for the random function

# %% Mixing for all the proportions of rain and snow efficiency in recharging groundwater

while (RAIN_EFF <= 1.):
	SNOW_EFF = 0.1
	while (SNOW_EFF <= 1.):
		
		filename = PATH + "RAIN_" + str(RAIN_EFF) + "_SNOW_" + str(SNOW_EFF) + ".csv"
		df = pd.read_csv(filename)
		
		# Computing the proportion of groundwater recharged from snow in long term
		recharge_rain_amount = sum(df["Rain recharge (mm)"].values)
		recharge_snow_amount = sum(df["Snow recharge (mm)"].values)
		actual_snow_ratio_long_term = recharge_snow_amount/(recharge_rain_amount+recharge_snow_amount)
		
		# Computing the proportion of groundwater recharged from snow in short term (corresponding to the isotopic data period)
		recharge_rain_amount = sum(df["Rain recharge (mm)"].values[(YEARS-LAST_YEARS)*365:])
		recharge_snow_amount = sum(df["Snow recharge (mm)"].values[(YEARS-LAST_YEARS)*365:])
		actual_snow_ratio_short_term = recharge_snow_amount/(recharge_rain_amount+recharge_snow_amount)

		# Building list containing isotopic ratio of rain, snowfall and groundwater
		random_rain_iso, random_snow_iso, random_gw_iso = [], [], []
		random_rain_amount, random_snow_amount = [], [] # Amount of rain and snowmelt corresponding to the isotopic ratio 
		for year_index in range(YEARS-LAST_YEARS, YEARS):
			for month in range(1, 13):
				
				# Subsetting the dataframe
				startDayNumb  = datetime.datetime(2001, month, 1).timetuple().tm_yday
				start_index = year_index * 365 + startDayNumb
				end_index = start_index + calendar.monthrange(2001, month)[1]
				
				# Rainfall amount and isotopic ratio
				rain_amount = df["Rainfall (mm)"].values[start_index: end_index+1] # Amount of rainfall
				rain_isotopic_ratio = df["Precip isotopic ratio"].values[start_index: end_index+1] # Isotopic ratio of rainfall
				
				# Amount of snowfall or snowmelt
				if (WHICH_SNOW == "Snowfall"):
					snow_amount = df["Snowfall (mm)"].values[start_index: end_index+1] # Amount of snowfall
					snow_isotopic_ratio = df["Precip isotopic ratio"].values[start_index: end_index+1] # Snowfall isotopic ratio
				elif (WHICH_SNOW == "Snowmelt"):
					snow_amount = df["Snowmelt (mm)"].values[start_index: end_index+1] # Amount of snowmelt
					# Shifted up by 1 row because the current snowmelt isotopic ratio is the snowpack isotopic ratio at the last timestep
					snow_isotopic_ratio = df["Snowpack isotopic ratio"].values[start_index-1: end_index] # Snowmelt isotopic ratio
					
				storage_isotopic_ratio = df["Storage isotopic ratio"].values[start_index: end_index+1] # Groundwater isotopic ratio

				# Only considering days when it rained or [snowed or the snow melted]
				rain_index = np.nonzero(rain_amount)[0] # Day when there was rain 
				snow_index = np.nonzero(snow_amount)[0] # Day when there was snowfall or snowmelt
				
				# Isotopic ratio of rainfall and snowfall/snowmelt
				rain_Iso, snow_Iso = rain_isotopic_ratio[rain_index], snow_isotopic_ratio[snow_index]
				# Magnitude of rainfall and snowfall/snowmelt
				temp_rain_amount, temp_snow_amount = rain_amount[rain_index], snow_amount[snow_index]

				# Choosing values of rain and snowfall/snowmelt isotopic ratio to be used in HydroMix
				if (len(rain_Iso) != 0):
#					# Randomly choose one monthly rainfall sample
#					random_rain_iso.append(random.sample(rain_Iso, 1)[0])
#					random_rain_amount.append(random.sample(temp_rain_amount)[0])
					
					# Choose all the rainfall samples
					random_rain_iso.extend(rain_Iso)
					random_rain_amount.extend(temp_rain_amount)
					
				if (len(snow_Iso) != 0):
#					# Randomly choose one monthly snowfall/snowmelt sample
#					random_snow_iso.append(random.sample(snow_Iso, 1)[0]) 
#					random_snow_amount.append(random.sample(temp_snow_amount, 1)[0])
					
					# Choose all the snowfall/snowmelt samples
					random_snow_iso.extend(snow_Iso)
					random_snow_amount.extend(temp_snow_amount)
				
				# Randomly choose one monthly groundwater sample
				random_gw_iso.append(random.sample(storage_isotopic_ratio, 1)[0])
								
		# Defining weights for rain and snowfall/snowmelt samples
		random_rain_weight = np.array([i*j for i, j in zip(random_rain_iso, random_rain_amount)]) / sum(random_rain_amount + random_snow_amount)
		random_snow_weight = np.array([i*j for i, j in zip(random_snow_iso, random_snow_amount)]) / sum(random_rain_amount + random_snow_amount)
		
		
		# Running the mixing model
		
		# List of initial parameter values 
		initParam = [np.random.uniform(LAMBDA_RANGE[0], LAMBDA_RANGE[1])]
		
		# Lower and upper limits of the model parameters
		paramLimit = [LAMBDA_RANGE]
		
		# Standard deviation of H2 in groundwater
		H2_std = np.std(random_gw_iso, ddof=1)
		
		if (WEIGHTED): # Running HydroMix taking into account weights
			LOGLIKELIHOOD_H2, PARAM_H2 = HydroMix_weighted(random_snow_iso, random_snow_weight, random_rain_iso, random_rain_weight, 
												  random_gw_iso, H2_std, initParam, paramLimit, NUMBER_ITERATIONS, JUMP_PERCENTAGE)
			snowRatioLis_H2 = [i[0] for i in PARAM_H2]
		else: # Running HydroMix without taking into account weights
			LOGLIKELIHOOD_H2, PARAM_H2 = HydroMix(random_snow_iso, random_rain_iso, random_gw_iso, H2_std, initParam, 
										 paramLimit, NUMBER_ITERATIONS, JUMP_PERCENTAGE)
			snowRatioLis_H2 = [i[0] for i in PARAM_H2]
			
		# Writing in a csv file	
		final_lis = [["Snow ratio", "Log likelihood", "Error std"]]
		path = OUTPUTPATH + "results_RAIN_" + str(RAIN_EFF) + "_SNOW_" + str(SNOW_EFF) + ".csv"
		for index in range(0, len(LOGLIKELIHOOD_H2)):
			final_lis.append([ round(snowRatioLis_H2[index], 4), round(LOGLIKELIHOOD_H2[index], 4), round(H2_std, 4) ])
		csv_writer(final_lis, path)
		print (path)
		
#		# Creating and saving figure
#		plt.figure(figsize=(10,6))
#		plt.hist(LAMBDA_H2[0:int(0.01 * BEST_SIM_PER * NUMBER_ITERATIONS)], color='blue', alpha=0.4, label=r'$\delta^{2}$H' + u' \u2030 (VSMOW)', normed='True')
#		plt.axvline(x=actual_snow_ratio_long_term, label='Groundwater recharged from snowmelt (long term)', color='red')
#		plt.axvline(x=actual_snow_ratio_short_term, label='Groundwater recharged from snowmelt (short term)', color='black')
#		plt.xlim(0., 1.)
#		plt.grid(linestyle='dotted')
#		plt.xlabel("Fraction of snow in groundwater", fontsize=14)
#		plt.ylabel("Normalised frequency", fontsize=14)
#		plt.legend()
#		plt.tight_layout()
#		path = OUTPUTPATH + "Figures/posterior_RAIN_" + str(RAIN_EFF) + "_SNOW_" + str(SNOW_EFF) + ".jpeg"
#		plt.savefig(path, dpi=300)
#		plt.close()
#		print (path)
		
		del df
		
		SNOW_EFF += 0.1
		
	RAIN_EFF += 0.1



#################################################################################################################################
